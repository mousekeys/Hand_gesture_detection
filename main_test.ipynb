{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KeyPointClassifier' from 'model' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyPointClassifier\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'KeyPointClassifier' from 'model' (unknown location)"
     ]
    }
   ],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import argparse\n",
    "import mediapipe as mdp\n",
    "import copy\n",
    "import os\n",
    "import csv\n",
    "from model import KeyPointClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETS THE REQUIRED ARGUMENTS IN CLI \n",
    "\n",
    "def get_args():\n",
    "    parser=argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--device\", type= int,default=0)\n",
    "    parser.add_argument(\"--staticimage\", action=\"store_true\")\n",
    "    parser.add_argument(\"--width\",help=\"Maximun width\", type= int,default=960)\n",
    "    parser.add_argument(\"--height\",help=\"Maximun height\", type= int,default=540)\n",
    "\n",
    "    parser.add_argument(\"--minDetection\" ,help=\"Minimum confidence for detection\",type=float,default=0.6)\n",
    "    parser.add_argument(\"--minTracking\" ,help=\"Minimum confidenxce for tracking\",type=float,default=0.8)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(use_static_image_mode,min_detection,min_tracking):\n",
    "\n",
    "#LOAD MODEL TO DETECT LANDMARKS IN HANDS\n",
    "    mdp_hands=mdp.solutions.hands\n",
    "    hands=mdp_hands.Hands(\n",
    "        static_image_mode=use_static_image_mode,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=min_detection,\n",
    "        min_tracking_confidence=min_tracking\n",
    "        )\n",
    "    return hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_input(cam_device,cam_width,cam_height):\n",
    "\n",
    "#POPERLY INITIALIZE CAMERA FOR WORKING\n",
    "    cam=cv2.VideoCapture(cam_device)\n",
    "    cam.set(cv2.CAP_PROP_FRAME_WIDTH,cam_width)\n",
    "    cam.set(cv2.CAP_PROP_FRAME_HEIGHT,cam_height)\n",
    "    return cam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW TO FIND THE EXACT COORDINATES IN THE SCREEN AS THE IMAGES ARE NORMALIZED RIGHT NPW\n",
    "\n",
    "def screen_coordinates(normalized_coodr,image):\n",
    "    img_height,img_width,_=image.shape\n",
    "\n",
    "    screen_coordinate=[]\n",
    "\n",
    "    for _,landmark in enumerate(normalized_coodr.landmark):\n",
    "        screen_x=int(landmark.x*img_width)\n",
    "        screen_y=int(landmark.y*img_height)\n",
    "        #NO NEED FOR LANDMARK Z AND ALSO IMAGE.SHAPE[2] PROVIDES COLOR INDEXES LIKE RGB SO 3\n",
    "        screen_coordinate.append([screen_x,screen_y])\n",
    "        cv2.circle(image, (screen_x, screen_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    return screen_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZATION SO THAT WE CAN DO SOMETHING EVEN WHEN THE HAND IS MOVED AND IT STILL WORKS ON THE HAND GEUSTURE\n",
    "#THE NORMALIZED POINTS MAKES IT SO THA WE NEED LESSER DATA AND SIMPLER MODEL TO TRAIN AND DETECT\n",
    "\n",
    "def normalized_values(screen_coordinate):\n",
    "\n",
    "    temp_landmark=copy.deepcopy(screen_coordinate)\n",
    "    base_x,base_y=0,0\n",
    "\n",
    "    print(type(temp_landmark))\n",
    "\n",
    "    for i, pixel_val in enumerate(temp_landmark):\n",
    "\n",
    "        if i==0:\n",
    "            base_x,base_y=screen_coordinate[0][0],screen_coordinate[0][1]\n",
    "        \n",
    "        temp_landmark[i][0]=pixel_val[0]-base_x\n",
    "        temp_landmark[i][1]=pixel_val[1]-base_y\n",
    "\n",
    "    # temp_landmark=np.array(temp_landmark).flatten()\n",
    "    temp_landmark = list(itertools.chain.from_iterable(temp_landmark))\n",
    "    max_val=max(list(map(abs,temp_landmark)))\n",
    "\n",
    "    def normalize_(val):\n",
    "        return val/max_val\n",
    "    \n",
    "    temp_landmark=list(map(normalize_,temp_landmark))\n",
    "\n",
    "    return temp_landmark\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW TO STORE THE DATAS IN A CSV FILE \n",
    "def store_data(number,normalized_one):\n",
    "    csv_path=r\"datas/pre_processed.csv\"\n",
    "    \n",
    "    with open(csv_path,'a',newline=\"\") as send:\n",
    "        store=csv.writer(send)\n",
    "        store.writerow([number,*normalized_one])\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['datas\\\\photos_hands\\\\1\\\\image copy.png',\n",
       "   'datas\\\\photos_hands\\\\1\\\\image.png'],\n",
       "  ['datas\\\\photos_hands\\\\2\\\\image.png']],\n",
       " [1, 2])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_path(path=''):\n",
    "    paths=[]\n",
    "    path_list=[]\n",
    "    pathx=[]\n",
    "    if not path:\n",
    "        path=r\"datas\\photos_hands\"\n",
    "    all_files=list(map(int,os.listdir(path)))\n",
    "\n",
    "    for i in range(len(all_files)):\n",
    "        paths.append(os.path.join(path,str(all_files[i])))\n",
    "    for path in paths:\n",
    "        path_list=[]\n",
    "        for i in os.listdir(path):\n",
    "            if i.endswith('.png'):\n",
    "                path_list.append(os.path.join(path,i))\n",
    "        pathx.append(list(path_list))\n",
    "        \n",
    "    return pathx,all_files\n",
    "\n",
    "image_path()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['datas\\\\photos_hands\\\\1\\\\image copy.png',\n",
       "   'datas\\\\photos_hands\\\\1\\\\image.png'],\n",
       "  ['datas\\\\photos_hands\\\\2\\\\image.png']],\n",
       " [1, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_boundrect(image,coodr):\n",
    "    x_val=[(i[0]) for i in coodr]\n",
    "    y_val=[(i[1]) for i in coodr]\n",
    "    x=min[x_val]\n",
    "    y=min[y_val]\n",
    "    w=max[x_val]-x\n",
    "    h=max[y_val]-y\n",
    "    return [x,y,x+w,y+h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results,hands,screen_coordinate):\n",
    "    mdp_hands = mdp.solutions.hands\n",
    "# Check if any hands are detected.\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw the landmarks on the image.\n",
    "            mdp.solutions.drawing_utils.draw_landmarks(\n",
    "                image, hand_landmarks, mdp_hands.HAND_CONNECTIONS,\n",
    "                mdp.solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mdp.solutions.drawing_styles.get_default_hand_connections_style()\n",
    "            )\n",
    "\n",
    "    # Display the image with landmarks.\n",
    "    cv2.imshow('Hand Landmarks', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['datas\\\\photos_hands\\\\1\\\\image copy.png', 'datas\\\\photos_hands\\\\1\\\\image.png'], ['datas\\\\photos_hands\\\\2\\\\image.png']]\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "# GET THE CAMERA ARGUMENTS FROM CLI COMMANDS\n",
    "    use_static_image_mode=True\n",
    "    min_detection=0.6\n",
    "    min_tracking=0.8\n",
    "\n",
    "\n",
    "    hands=load_models(use_static_image_mode,min_detection,min_tracking)\n",
    "    paths,num=image_path()\n",
    "    idx=0\n",
    "    print(paths)\n",
    "    for path in paths:\n",
    "        for i in path:\n",
    "            image=cv2.imread(i)\n",
    "            image = cv2.flip(image, 1)\n",
    "            # image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            final_img=copy.deepcopy(image)\n",
    "            \n",
    "            image.flags.writeable = False\n",
    "            results = hands.process(image)\n",
    "            image.flags.writeable = True\n",
    "    \n",
    "            screen_coordinate=screen_coordinates(results.multi_hand_landmarks[0],final_img)\n",
    "           \n",
    "            normalized_coodr=normalized_values(screen_coordinate)\n",
    "\n",
    "            final_img=draw_landmarks(final_img,results,hands,screen_coordinate)\n",
    "            store_data(num[idx],normalized_coodr)\n",
    "          \n",
    "          \n",
    "        idx=+1\n",
    "        cv2.destroyAllWindows()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_rect(image,rect):\n",
    "    cv2.rectangle(image, (rect[0], rect[1]), (rect[2], rect[3]),(0, 0, 0), 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyPointClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m simpleclassifier\u001b[38;5;241m=\u001b[39m\u001b[43mKeyPointClassifier\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KeyPointClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "simpleclassifier=KeyPointClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m     cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     58\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m---> 59\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m hands\u001b[38;5;241m=\u001b[39mload_models(use_static_image_mode,min_detection,min_tracking)\n\u001b[0;32m     13\u001b[0m mdp_hands \u001b[38;5;241m=\u001b[39m mdp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n\u001b[1;32m---> 16\u001b[0m simpleclassifier\u001b[38;5;241m=\u001b[39m\u001b[43mSimpleClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Process Key (ESC: end) #################################################\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # GET THE CAMERA ARGUMENTS FROM CLI COMMANDS\n",
    "    cam_device=0\n",
    "    cam_width=960\n",
    "    cam_height=540\n",
    "# GET THE CAMERA ARGUMENTS FROM CLI COMMANDS\n",
    "    use_static_image_mode=True\n",
    "    min_detection=0.6\n",
    "    min_tracking=0.8\n",
    "\n",
    "    cam=camera_input(cam_device,cam_width,cam_height)\n",
    "    hands=load_models(use_static_image_mode,min_detection,min_tracking)\n",
    "    mdp_hands = mdp.solutions.hands\n",
    "  \n",
    "\n",
    "    simpleclassifier=SimpleClassifier()\n",
    "    \n",
    "    while True:\n",
    "        # Process Key (ESC: end) #################################################\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        \n",
    "\n",
    "        # Camera capture #####################################################\n",
    "        ret, image = cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv2.flip(image, 1)  # Mirror display\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        if results.multi_hand_landmarks: \n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
    "                # print(results.multi_hand_landmarks[0])\n",
    "                screen_coordinate=screen_coordinates(results.multi_hand_landmarks[0],image)\n",
    "                normalized_coodr=normalized_values(screen_coordinate)\n",
    "                classification_id = simpleclassifier(normalized_coodr)\n",
    "                print(classification_id)\n",
    "                bound_rect=calc_bounding_rect(debug_image,results.multi_hand_landmarks[0])\n",
    "                \n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    # Draw the landmarks on the image.\n",
    "                    mdp.solutions.drawing_utils.draw_landmarks(\n",
    "                    debug_image, hand_landmarks, mdp_hands.HAND_CONNECTIONS,\n",
    "                    mdp.solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mdp.solutions.drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "                    \n",
    "                debug_image = draw_bounding_rect(debug_image, bound_rect)\n",
    "\n",
    "        cv2.imshow('Hand Gesturet', debug_image)\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands.\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Load the image.\n",
    "image = cv2.imread(r'C:\\Users\\sinju\\Documents\\HandsDetectSign\\Hand_gesture_detection\\datas\\photos_hands\\1\\image copy.png')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Process the image to find hands.\n",
    "results = hands.process(image_rgb)\n",
    "\n",
    "# Check if any hands are detected.\n",
    "if results.multi_hand_landmarks:\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        # Convert normalized coordinates to pixel coordinates.\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            x_px = int(landmark.x * width)\n",
    "            y_px = int(landmark.y * height)\n",
    "            # Draw a circle at each landmark.\n",
    "            cv2.circle(image, (x_px, y_px), 5, (0, 255, 0), -1)\n",
    "\n",
    "# Display the image with landmarks.\n",
    "cv2.imshow('Hand Landmarks', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_device=0\n",
    "cam_width=960\n",
    "cam_height=540\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camerastuff(cam_device,cam_width,cam_height):\n",
    "    cam=cv2.VideoCapture(cam_device)\n",
    "    while True:\n",
    "        cam.set(cv2.CAP_PROP_FRAME_WIDTH,cam_width)\n",
    "        cam.set(cv2.CAP_PROP_FRAME_HEIGHT,cam_height)\n",
    "        # Process Key (ESC: end) #################################################\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        \n",
    "\n",
    "        # Camera capture #####################################################\n",
    "        ret, image = cam.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv2.flip(image, 1)  # Mirror display\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        cv2.imshow('Hand Gesture Recognition', image)\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../datas/photos_hands'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datas/pre_processed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m folder_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datas/photos_hands\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m all_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m,(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m      5\u001b[0m all_num\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../datas/photos_hands'"
     ]
    }
   ],
   "source": [
    "csv_path=\"../datas/pre_processed.csv\"\n",
    "folder_path=\"../datas/photos_hands\"\n",
    "all_num=list(map(int,(os.listdir(folder_path))))\n",
    "\n",
    "all_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=results.multi_hand_landmarks\n",
    "for i,val in enumerate(x[0].landmark):\n",
    "    print(val.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to process hand landmarks\n",
    "def process_hand_landmarks(hand_landmarks: landmark_pb2.NormalizedLandmarkList):\n",
    "    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "        print(f'Landmark {idx}: x={landmark.x}, y={landmark.y}, z={landmark.z}')\n",
    "\n",
    "# Example usage with dummy data\n",
    "example_landmarks = landmark_pb2.NormalizedLandmarkList()\n",
    "example_landmarks.landmark.add(x=0.5, y=0.5, z=0.5)\n",
    "example_landmarks.landmark.add(x=0.6, y=0.6, z=0.6)\n",
    "\n",
    "process_hand_landmarks(example_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=main()\n",
    "output_dict = results.__dict__\n",
    "\n",
    "# Print the entire dictionary\n",
    "for key, value in output_dict.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "media",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
